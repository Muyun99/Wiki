---
title: Transformer系列代码
date: 2021-10-16 20:57:31
permalink: /pages/b34b2b/
categories:
  - 学习笔记
  - 代码实践-图像分割
tags:
  - 
---
可解释性：https://github.com/hila-chefer/Transformer-Explainability



## CrossFormer: https://github.com/cheerss/CrossFormer

#### ADE20K

| Backbone          | Segmentation Head | Iterations | Params     | FLOPs       | IOU      | MS IOU   |
| ----------------- | ----------------- | ---------- | ---------- | ----------- | -------- | -------- |
| **CrossFormer-S** | FPN               | 80K        | **34.3M**  | **209.8G**  | **46.4** | -        |
| **CrossFormer-B** | FPN               | 80K        | **55.6M**  | **320.1G**  | **48.0** | -        |
| **CrossFormer-L** | FPN               | 80K        | **95.4M**  | **482.7G**  | **49.1** | -        |
| ResNet-101        | UPerNet           | 160K       | 86.0M      | 1029.G      | 44.9     | -        |
| **CrossFormer-S** | UPerNet           | 160K       | **62.3M**  | **979.5G**  | **47.6** | **48.4** |
| **CrossFormer-B** | UPerNet           | 160K       | **83.6M**  | **1089.7G** | **49.7** | **50.6** |
| **CrossFormer-L** | UPerNet           | 160K       | **125.5M** | **1257.8G** | **50.4** | **51.4** |



## Swin-Transformer: https://github.com/SwinTransformer/Swin-Transformer-Semantic-Segmentation

#### ADE20K

| Backbone | Method  | Crop Size | Lr Schd | mIoU  | mIoU (ms+flip) | #params | FLOPs |
| -------- | ------- | --------- | ------- | ----- | -------------- | ------- | ----- |
| Swin-T   | UPerNet | 512x512   | 160K    | 44.51 | 45.81          | 60M     | 945G  |
| Swin-S   | UperNet | 512x512   | 160K    | 47.64 | 49.47          | 81M     | 1038G |
| Swin-B   | UperNet | 512x512   | 160K    | 48.13 | 49.72          | 121M    | 1188G |



## Residual Attention: A Simple but Effective Method for Multi-Label Recognition: https://github.com/Kevinz-code/CSRA

| Dataset | Backbone    | Head nums | mAP(%) | Resolution | Download                                                     |
| ------- | ----------- | --------- | ------ | ---------- | ------------------------------------------------------------ |
| VOC2007 | ResNet-101  | 1         | 94.7   | 448x448    | [download](https://drive.google.com/u/0/uc?export=download&confirm=bXcv&id=1cQSRI_DWyKpLa0tvxltoH9rM4IZMIEWJ) |
| VOC2007 | ResNet-cut  | 1         | 95.2   | 448x448    | [download](https://drive.google.com/u/0/uc?export=download&confirm=otx_&id=1bzSsWhGG-zUNQRMB7rQCuPMqLZjnrzFh) |
| COCO    | ResNet-101  | 4         | 83.3   | 448x448    | [download](https://drive.google.com/u/0/uc?export=download&confirm=EWtH&id=1e_WzdVgF_sQc--ubN-DRnGVbbJGSJEZa) |
| COCO    | ResNet-cut  | 6         | 85.6   | 448x448    | [download](https://drive.google.com/u/0/uc?export=download&confirm=uEcu&id=17FgLUe_vr5sJX6_TT-MPdP5TYYAcVEPF) |
| Wider   | VIT_B16_224 | 1         | 89.0   | 224x224    | [download](https://drive.google.com/u/0/uc?id=1qkJgWQ2EOYri8ITLth_wgnR4kEsv0bfj&export=download) |
| Wider   | VIT_L16_224 | 1         | 90.2   | 224x224    | [download](https://drive.google.com/u/0/uc?id=1da8D7UP9cMCgKO0bb1gyRvVqYoZ3Wh7O&export=download) |





## CMT: Convolutional Neural Networks Meet Vision Transformers



## **Pre**-Trained Image Processing Transformer (IPT)

https://github.com/huawei-noah/Pretrained-IPT



## HRFormer: High-Resolution Transformer for Dense Prediction, NeurIPS 2021

https://github.com/HRNet/HRFormer

#### ADE20K

| Methods | Backbone   | Window Size | Train Set | Test Set | Iterations | Batch Size | OHEM | mIoU | mIoU (Multi-Scale) | Log                                                          | ckpt                                                         | script                                                       |
| ------- | ---------- | ----------- | --------- | -------- | ---------- | ---------- | ---- | ---- | ------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| OCRNet  | HRFormer-S | 7x7         | Train     | Val      | 150000     | 8          | Yes  | 44.0 | 45.1               | [log](https://1drv.ms/u/s!Ai-PFrdirDvwj3EehoEZZUDMX0NU?e=F8HAQi) | [ckpt](https://1drv.ms/u/s!Ai-PFrdirDvwj28i74aN6_Zk4clX?e=CWGOcd) | [script](https://github.com/HRNet/HRFormer/blob/main/seg/scripts/ade20k/hrt/run_hrt_small_ocr_v2_ohem.sh) |
| OCRNet  | HRFormer-B | 7x7         | Train     | Val      | 150000     | 8          | Yes  | 46.3 | 47.6               | [log](https://1drv.ms/u/s!Ai-PFrdirDvwj265qyyZ74PKjfqm?e=Cj7TGl) | [ckpt](https://1drv.ms/u/s!Ai-PFrdirDvwj3epNJ-QFF33tZtr?e=df3fQk) | [script](https://github.com/HRNet/HRFormer/blob/main/seg/scripts/ade20k/hrt/run_hrt_base_ocr_v2_ohem.sh) |
| OCRNet  | HRFormer-B | 13x13       | Train     | Val      | 150000     | 8          | Yes  | 48.7 | 50.0               | [log](https://1drv.ms/u/s!Ai-PFrdirDvwkAjmpl5jj0sXz2v-?e=sfhyI4) | [ckpt](https://1drv.ms/u/s!Ai-PFrdirDvwj3oTs_gVPzFDjdyU?e=yjGRKz) | [script](https://github.com/HRNet/HRFormer/blob/main/seg/scripts/ade20k/hrt/run_hrt_base_ocr_v2_ohem_w13.sh) |
| OCRNet  | HRFormer-B | 15x15       | Train     | Val      | 150000     | 8          | Yes  | -    | -                  | -                                                            | -                                                            | -                                                            |







## DeiT: Data-efficient Image Transformers

https://github.com/facebookresearch/deit

#### Model Zoo

We provide baseline DeiT models pretrained on ImageNet 2012.

| name                                  | acc@1 | acc@5 | #params | url                                                          |
| ------------------------------------- | ----- | ----- | ------- | ------------------------------------------------------------ |
| DeiT-tiny                             | 72.2  | 91.1  | 5M      | [model](https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth) |
| DeiT-small                            | 79.9  | 95.0  | 22M     | [model](https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth) |
| DeiT-base                             | 81.8  | 95.6  | 86M     | [model](https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth) |
| DeiT-tiny distilled                   | 74.5  | 91.9  | 6M      | [model](https://dl.fbaipublicfiles.com/deit/deit_tiny_distilled_patch16_224-b40b3cf7.pth) |
| DeiT-small distilled                  | 81.2  | 95.4  | 22M     | [model](https://dl.fbaipublicfiles.com/deit/deit_small_distilled_patch16_224-649709d9.pth) |
| DeiT-base distilled                   | 83.4  | 96.5  | 87M     | [model](https://dl.fbaipublicfiles.com/deit/deit_base_distilled_patch16_224-df68dfff.pth) |
| DeiT-base 384                         | 82.9  | 96.2  | 87M     | [model](https://dl.fbaipublicfiles.com/deit/deit_base_patch16_384-8de9b5d1.pth) |
| DeiT-base distilled 384 (1000 epochs) | 85.2  | 97.2  | 88M     | [model](https://dl.fbaipublicfiles.com/deit/deit_base_distilled_patch16_384-d0272ac0.pth) |
| CaiT-S24 distilled 384                | 85.1  | 97.3  | 47M     | [model](https://github.com/facebookresearch/deit/blob/main/README_cait.md) |
| CaiT-M48 distilled 448                | 86.5  | 97.7  | 356M    | [model](https://github.com/facebookresearch/deit/blob/main/README_cait.md) |



## Efficient Vision Transformers via Fine-Grained Manifold Distillation

https://arxiv.org/abs/2107.01378



## Augmented Shortcuts for Vision Transformers

https://arxiv.org/abs/2106.15941

Attention Map  的 rank 和多样性



## SOFT: Softmax-free Transformer with Linear Complexity

https://github.com/fudan-zvg/SOFT

### Image Classification

#### ImageNet-1K

| Model       | Resolution | Params | FLOPs | Top-1 % | Config                                                       |
| ----------- | ---------- | ------ | ----- | ------- | ------------------------------------------------------------ |
| SOFT-Tiny   | 224        | 13M    | 1.9G  | 79.3    | [SOFT_Tiny.yaml](https://github.com/fudan-zvg/SOFT/blob/master/config/SOFT_Tiny.yaml), [SOFT_Tiny_cuda.yaml](https://github.com/fudan-zvg/SOFT/blob/master/config/SOFT_Tiny_cuda.yaml) |
| SOFT-Small  | 224        | 24M    | 3.3G  | 82.2    | [SOFT_Small.yaml](https://github.com/fudan-zvg/SOFT/blob/master/config/SOFT_Small.yaml), [SOFT_Small_cuda.yaml](https://github.com/fudan-zvg/SOFT/blob/master/config/SOFT_Small_cuda.yaml) |
| SOFT-Medium | 224        | 45M    | 7.2G  | 82.9    | [SOFT_Meidum.yaml](https://github.com/fudan-zvg/SOFT/blob/master/config/SOFT_Medium.yaml), [SOFT_Meidum_cuda.yaml](https://github.com/fudan-zvg/SOFT/blob/master/config/SOFT_Medium_cuda.yaml) |
| SOFT-Large  | 224        | 64M    | 11.0G | 83.1    | [SOFT_Large.yaml](https://github.com/fudan-zvg/SOFT/blob/master/config/SOFT_Large.yaml), [SOFT_Large_cuda.yaml](https://github.com/fudan-zvg/SOFT/blob/master/config/SOFT_Large_cuda.yaml) |
| SOFT-Huge   | 224        | 87M    | 16.3G | 83.3    | [SOFT_Huge.yaml](https://github.com/fudan-zvg/SOFT/blob/master/config/SOFT_Huge.yaml), [SOFT_Huge_cuda.yaml](https://github.com/fudan-zvg/SOFT/blob/master/config/SOFT_Huge_cuda.yaml) |