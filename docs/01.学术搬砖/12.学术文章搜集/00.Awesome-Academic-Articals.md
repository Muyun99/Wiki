---
title: Awesome-weakly-supervised-semantic-segmentation
date: 2021-10-14 13:24:30
permalink: /pages/865735/
categories:
  - 学术搬砖
  - 论文阅读-弱监督图像分割
tags:
  - 
---


Tricks

- CAN：借助先验分布提升分类性能的简单后处理技巧：https://kexue.fm/archives/8728
  - 用先验分布来校正低置信度的预测结果，使得新的预测结果的分布更接近先验分布。



知识蒸馏

- [KDD 2020 | 优势特征蒸馏在淘宝推荐中的应用](https://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ%3D%3D&mid=2650414918&idx=3&sn=59497d8b36c6626c5791e4010b160ab8&hmsr=joyk.com&utm_source=joyk.com&utm_medium=referral)

- [深度学习中的知识蒸馏技术（上）](https://mp.weixin.qq.com/s?__biz=MzI5NDMzMjY1MA==&mid=2247486684&idx=1&sn=1f0fbd6ac3b4ef4be9d150838ea29d71&chksm=ec653d59db12b44fda22c18e8bc73632d7fb814197ee4f319cc7a863c18aaace83acc13ad14c&scene=21#wechat_redirect)



图像分割

- [单阶段实例分割综述](https://mp.weixin.qq.com/s?__biz=MzkyMDE2OTA3Mw==&mid=2247491327&idx=1&sn=69e695fbfc5d60ece5328935a36164f9&chksm=c197a1e1f6e028f7e5bc64fb0a291e72a4d45bdc9688e4e4f084b51148f90e57b9ff137b6ad0&token=114217079&lang=zh_CN#rd)



端侧网络

- 反向 Dropout！韩松团队最新工作NetAug：https://mp.weixin.qq.com/s/tBEpRZ3mAQpEmc27g2HuEA
  - 现有的正则技术(比如数据增强、dropout)在大网络方面(比如ResNet50)方面通过添加噪声使其避免过拟合取得了极大成功。然而，我们发现：**这些正则技术会损害TinyNN的性能(见下图)。** 我们认为：**不同于大网络通过增广数据提升性能，TinyNN应当通过增广模型提升性能** 。这是因为：**受限于模型大小，TinyNN往往存在欠拟合现象而非过拟合** 。