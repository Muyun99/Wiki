---
title: DMT Dynamic Mutual Training for Semi-Supervised Learning
date: 2021-04-20 10:07:30
permalink: /pages/fa84fb/
categories:
  - 论文阅读
  - 图像分割
tags:
  - 
---
# DMT: Dynamic Mutual Training for Semi-Supervised Learning

#### 作者：商汤 Jianping Shi、上交 DMCV 实验室

#### 发表：Arixiv 准备投 PR

#### 摘要

近期的半监督学习方法将利用伪标签作为核心思想，但是伪标签并不可靠。自训练的方法依赖于单模型预测的置信度来过滤掉低置信度的伪标签，但是存在以下问题：有概率保留高置信度的带噪样本以及丢弃掉低置信度的正确样本。在这篇论文中，我们指出模型很难发现自己的错误，相反利用不同模型间的差异是定位伪标签错误的关键。从这个新角度出发，我们提出了在两个不同的模型中互训练，并利用一个动态重加权的损失函数，称作动态互训练（DMT），通过比较两种不同模型的预测以动态分配训练中的权重，来量化模型间的分歧，较大的分歧表示较高概率的错误，并对应较低的损失值，实验证明 DMT 能够在图像分类和图像分割上都能达到 SOTA 的结果。

#### 阅读

#### 论文的目的及结论

想通过比较两种不同模型的预测来动态分配训练中样本的权重，最终能够在图像分类和图像分割上都能达到 SOTA 的结果。

#### 论文的实验

对于图像分类任务，在 CIFAR-10 上做了实验。对于语义分割任务，在 PASCAL VOC 2012 和 Cityscapes 数据及上做了实验。由于 DMT 在迭代框架中能够有更好的性能以及快速的收敛，所有的 DMT 实验都默认 5 次迭代，在单张 RTX2080 Ti GPU 上做实验，全监督的学习结果被称作 Oracle，作为半监督学习结果的上限。然而由于全监督的标注中也有噪声，我们的 DMT 方法可以超过全监督方法得到的性能。

##### 1、超参数调整

![image-20210420135652542](https://muyun-blog-pic.oss-cn-shanghai.aliyuncs.com/picgo/image-20210420135652542.png)

为了避免太多的超参数调整，作者设置 $\gamma_1=\gamma_2$ ，我们有确定的比例（例如 labeled：unlabeled = 1：7），更多的细节在上述的表一中都列出来

###### 图像分类

**训练阶段：**网络架构使用 MixMatch 中的设置 WideResNet-28-2 作为 backbone。每个 DMT 迭代是 750 epochs，学习率为 0.1，权重衰减为 $5 \times 10^{-4}$ ，动量设置为 0.9，余弦学习率调整器以及 512 的batch size，与 [26] 的课程学习实验设置相同，为了公平比较，作者并未使用 [32] 中提出的 SWA 技巧。数据增强是 带有 Cutout 的 RandAugment[33]，在每一个 step 中随机选择一种随机强度的增强操作以避免超参数的调整，并且使用 Mixup来应用动态权重

**测试阶段**：五次测试的平均，指数移动平均网络（follow 了 MixMatch[11]）



###### 语义分割

**训练阶段：**follow 了 [8, 12] 的方法使用 DeepLab-v2 ResNet-101 作为 backbone，没有多尺度融合以及 CRF 的后处理，作者的方法性能能够显著地超过以前方法的性能。由于使用了fine-tuning，分割任务的每个 DMT 迭代需要更少的训练 step，使用 SGD 优化器 （Momentum 为 0.9，lr schedule 为 poly, batch size 为 8），数据增强包括随机缩放，随机裁剪以及随机翻转，训练的尺度为 $321\times321$ (PASCAL VOC 2012) 以及 $256\times512$ (Cityscapes)

**测试阶段：** 三次测试的平均

##### 2、性能的比较

###### 图像分类

![image-20210420140836417](https://muyun-blog-pic.oss-cn-shanghai.aliyuncs.com/picgo/image-20210420140836417.png)

和 Mean Teacher(MT) [9]，Curriculum Labeling(CL)[26]，Deep Co-Training (DCT)[15]，Dual Student(DS)[35]，MixMatch[11]，DAG[36] 方法进行比较，在 1k 和 4k 的标签划分下都进行了比较。带有 mixup 以及 其他数据增强的全监督性能作为Baseline，Baseline，CL，DMT 使用同一套 codebase 来实现，其他的方法都从原始论文中获取

###### 语义分割

和 

#### 论文的方法



#### 论文的背景



#### 总结

##### 论文的贡献

##### 论文的不足

##### 论文如何讲故事

#### 参考资料

- https://arxiv.org/abs/2004.08514

- https://github.com/voldemortX/DST-CBC