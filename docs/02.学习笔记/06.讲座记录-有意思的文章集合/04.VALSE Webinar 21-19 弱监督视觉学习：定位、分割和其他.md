---
title: VALSE Webinar 21-19 弱监督视觉学习：定位、分割和其他
date: 2021-07-16 23:39:49
permalink: /pages/ada345/
categories:
  - 技术文章
  - 有意思的文章集合
tags:
  - 
---
## VALSE Webinar 21-19 弱监督视觉学习：定位、分割和其他

### 万方 中国科学院大学

#### 1、扩散激活：DANet: Divergent Activation for Weakly Supervised Object Localization. ICCV 2019

（1）分层激活：Hierarchical Divergent Activation（HDA），试图对类别做做一个分层，先做父类的分类，再做子类别的分类。多尺度 CNN 得到特征金字塔，特征金字塔每一层有不同的激活区域

（2）分歧激活：Discrepant Dovergent Activation（DDA），通过分歧约束，实现输出的激活图是有分歧的，将多个有分歧的 CAM 合并可以得到更完整的激活区域

#### 2、增强学习容忍度：Strengthen Learning Tolerance for Weakly Supervised Object Localization. CVPR 2021

（1）对 top-k 的类别都进行一个判别，对语义相似的区域也会进行激活，再将结果合并

（2）对图像做变换后，输出的 CAM 是有一致性的

#### 3、Transformer 有全局表示的特性：Transformer-Based Method：TS-CAM: Token Semantic Coupled Attention Map for Weakly Supervised Object Localization. arXiv 2021

（1）Transformer 对于目标的激活图是比较完整的，但是 Attention Map 是语义无关的，会将所有的类别的 Attention 全部输出

（2）设计了一个语义相关的结构用于获取 Attention Map

### 肖继民 西交利物浦大学

#### 1、扩散激活：Reliability Dose Matter: An End-to-End Weakly Supervised Semantic Segmentation Approach. AAAI 2020

（1）端到端的去做弱监督语义分割

（2）multi-scale CAM：做多尺度的CAM的测试然后进行融合

（3）loss 分为两部分：对高置信度的区域做CE loss，Energy Loss是融合了 CRF Loss 和 一个loss weight，reliable region 有更小的 loss weight，相邻的点和颜色相近的点预测成同一类，如果不是同一类则进行惩罚

（4）这篇工作最大的亮点是端到端，据说是第二篇端到端的工作

#### 2、显著性目标检测：Structure-Consistent Weakly Supervised Salient Object Detection with Local Saliency Coherence. AAAI 2021

（1）改造版本的CRF Loss

（2）Saliency Structure Consistency Loss：先CAM再增强和先增强后CAM的结果做一个一致性 loss，与SEAM一致

#### 3、图模型做弱监督分割：Affinity Attention Graph Neural Network for Weakly Supervised Semantic Segmentation. IEEE TPAMI 2021

（1）将 image 转换为 graph，提出以下几点

- 每个 feature pixel 作为 node，而不是super pixel
- 对于任意两个 node 之间都有 edge
- Edge 的值不止是 0  和 1

（2）bbox 的 label  + image label 

- image label：CAM
- bbox label：Grab-Cut 
- 两个区域的作为 seed label

（3）如何将 Image 转换为 Graph？

- 借鉴并改进 Affinity CNN
- 下面是 Ac Loss 的计算过程，只针对可靠区域计算
- 在一定距离范围内，如果两个node类别信息一致，其edge值为1，加入 A+ 集合，否则为0，加入 A- 集合
- 如何获得两个点的预测的边呢：两个点的feature做一个L1 loss（未听清），得到 D(i,j) 
- 下面是 Ar Loss 的计算过程，不限制区域，对所有区域都计算



### Pannel 环节

#### 1、图像中的背景区域较为杂乱，导致背景类样本具有较大的类内散度，进而导致背景类自身难以准确建模，同时影响其他语义类别的建模，这个问题如何解决？

1、类别无关的物体定位

2、Positive Unlabel Learning，PU学习

3、引入主动学习引入较为精确的标注

4、类内散度不影响，前景背景类较为相似导致的问题，更加强大的预训练模型

#### 2、样本 label noise 的问题怎么解决？

1、图像和标注进行质量评估，对于学习的影响也会比较大，课程学习，先用简单样本，再用难样本

2、如何改造我们的全监督网络，让其的容错性更加高

3、DNN 在比较大的噪声标注下还是比较鲁棒的（我觉得应当是对于分割来说的），co-training，

4、co-training，Transformer 和 CNN 不同性质的网络

5、label noise主要两个来源：伪标签和众包标注，通过软标记来解决噪声问题

**耿新老师：做伪标记的时候，用一个标记分布，用图神经网络做软标记？**

**co-training + 标记分布，多模型都给一个标记分布**

#### 3、现在的弱监督学习基本还是沿用MIL的建模方式，目前是否有其他的机器学习模型适用于弱监督学习？

1、自学习，带噪声的半监督学习，Transformer和自监督Transformer可能会有更好的效果（DINO）

2、特征空间的规整，在特征学习和后续的分类器做一个 match，新的联合优化的方式

3、标记不完整（半监督，PU学习），不正确（label noise），不精确（image-lavel annotation，MIL，偏标记学习）

#### 4、弱监督下模型复杂度从理论上是否与效果成正相关？不准确、不全面的标注是否更加难以训练较大规模的网络模型？

1、噪声非常大，大规模网络表现不好，例如 DeepLabv2 性能是比较好的，动态调整网络的复杂度

2、Scaled-ViT , 标签噪声有多大，对表示学习的模型会产生什么特征空间，特征空间会产生什么，理论上给一个定义

3、问题复杂度增加了，机器学习模型的复杂度应当增加。用最匹配的模型来解决

#### 5、弱监督学习在什么条件下可以逼近强监督学习的效果？什么场景下可以充分发挥弱监督学习的优势？

1、弱监督学习的问题在于：前背景的界限过于模糊

2、标注强一些，线标或者框标，只有3个点左右的gap，如果只有image-lavel的标注会带来10个点左右的差距，弱监督可以结合半监督，

3、显著性信息的引入，合理地引入先验

4、学习问题的一致性，理论上来讲，数据量是无穷大的时候，可以逼近强监督学习的效果；减小搜索空间：先验知识等等

#### 6、当前弱监督学习的核心挑战是什么？当数据不再能驱得动学习过程，是否应该回归模型驱动的学习方法？

1、王：复杂场景的弱监督：引入视觉规律，显著性，边缘（**有无纹理**），超像素

2、叶：表示学习的挑战是一样的，不完全标注、部分标注、现有的信息来估计不完全的信息，能够处理数据的Varience，传统方法引入也不失为一种策略：几何模型

3、耿：小样本弱监督学习（医疗影像），边际递减效应，不断增加数据获得的收益会逐步递减，回归模型驱动，比如决策树，SVM，压缩感知等等

#### 7、弱监督学习在学术界和工业界的未来研究趋势是什么？是否需要新的benchmark？如何定义新的benchmark?

1、万：主动学习、无监督学习结合

2、肖：工业界的在固定的标注代价下，怎么提升最大的收益，标注的组合，领域迁移的工作

3、王：互联网和医院，抗疫的工作

4、叶：工业界可以利用弱监督学习去获取预训练模型，学术界应该探索新的范式，与无监督和表示学习之间的关系，视频的标注量

5、耿：工业界关心的成本问题，先验知识，模型和数据的匹配，元学习