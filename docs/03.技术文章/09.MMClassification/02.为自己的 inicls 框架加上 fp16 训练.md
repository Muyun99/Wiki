---
title: 为自己的 inicls 框架加上 fp16 训练
date: 2021-07-13 21:14:11
permalink: /pages/e677b8/
categories:
  - 技术文章
  - MMClassification
tags:
  - 
---
# 为自己的 inicls 框架加上 fp16 训练

### 01、如何实现

不得不说现在的库封装的都特别好，核心代码就加了几行

```python
from torch.cuda.amp import GradScaler, autocast


for iteration in range(max_iteration):
    optimizer.zero_grad()

    if cfg.fp16 is True:
        with autocast():
            # model做一个FP16的副本，forward
            logits = model(images)
            loss = criterion(logits, labels).mean()
        scaler.scale(loss).backward()
        # scaler 更新参数，会先自动unscale梯度
        # 如果有nan或inf，自动跳过
        scaler.step(optimizer)
        # scaler factor更新
        scaler.update()
    else:
        logits = model(images)
        loss = criterion(logits, labels).mean()
        loss.backward()
        optimizer.step()
```

```python
if cfg.fp16:
	with autocast():
		logits = model(images)
else:
	logits = model(images)
```



### 02、效果比较

#### 2.1 脚本介绍

实验的脚本非常简单，不得不说搭了这个框架之后做一些普通实验是真的很方便

```bash
export CUDA_VISIBLE_DEVICES=0
python train.py config/resnet/resnet18_b16x8_kaggle_leaves.py --tag resnet_fp16 --options "fp16=True" "data.train.ann_file=train_fold0.csv" "data.val.ann_file=valid_fold0.csv"

python train.py config/resnet/resnet18_b16x8_kaggle_leaves.py --tag resnet_not_fp16 --options "data.train.ann_file=train_fold0.csv" "data.val.ann_file=valid_fold0.csv"
```

#### 2.2 速度、显存、性能对比

| 实验名称              | 学习率 | 验证集上最优精度 | 训练时间 | 显存占用 | 备注                                                         |
| --------------------- | ------ | ---------------- | -------- | -------- | ------------------------------------------------------------ |
| resnet_fp16_lr_0.1    | 0.1    | 0.9553           | 13m27s   | 2300MiB  | 在 6k iteration 之后 loss 变为 nan                           |
| resnet_fp16_lr_0.01   | 0.01   | 0.9455           | 12m59s   | 2300MiB  | 在 5k iteration 之后 loss 变为 nan                           |
| resnet_fp16_lr_0.001  | 0.001  | 0.7126           | 13m31s   | 2300MiB  | 在 4k iteration 之后 loss 变为 nan                           |
| resnet_nofp16_lr_0.1  | 0.1    | 0.9651           | 19m19s   |          |                                                              |
| resnet_fp16_lr_0.1_v3 | 0.1    | 0.9635           | 12m10s   | 4360MiB  | batch_size 改为 256，并且 loss 并未变为 nan                  |
| resnet_fp16_lr_0.1_v4 | 0.1    | 0.9624           | 50m29s   | 4360MiB  | batch_size 改为 256，并且将epoch 改为 200，在 8k iteration 之后 loss 变为 nan |

### 03、loss 变为nan

在我用默认配置跑的时候，发现在 7k 左右的 iteration ，loss 会突变为 nan，目前尚不知是什么原因，先尝试了把学习率给调低，并没有什么影响

然后把 batch_size调高了发现不会出现nan了，

下面尝试讲 batch_size 调高的同时加大epoch数





### 04、mmcls 是如何实现 fp16 训练的呢

参考资料：

- [PyTorch 源码解读之 torch.cuda.amp: 自动混合精度详解](https://zhuanlan.zhihu.com/p/348554267)

- [浅谈混合精度训练 imagenet](https://bbs.cvmart.net/articles/5090)

