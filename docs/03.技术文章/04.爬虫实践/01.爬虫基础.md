---
title: 爬虫基础
date: 2021-03-09 21:20:55
permalink: /pages/2cfd0e/
categories:
  - 技术文章
  - 爬虫实践
tags:
  - 
---

### Python 爬虫 -01 爬虫基础

#### 1 HTTP

HTTP是一个客户端（用户）和服务器端（网站）之间进行请求和应答的标准。通过使用网页浏览器、网络爬虫或者其他工具，客户端可以向服务器上的指定端口（默认端口为80）发起一个HTTP请求。客户端称为客户代理（user agent），应答服务器成为源服务器（origin server)。

HTTP假定其下层协议能够提供可靠的传输，因此，任何能够提供这种保证的协议都可以使用。使用TCP/IP协议族时RCP(Remote Procedure Call，远程过程调用)作为传输层

通常由HTTP客户端发起一个请求，创建一个到服务器指定端口（默认是80端口）的TCP链接。HTTP服务器则在该端口监听客户端的请求。一旦收到请求，服务器会向客户端返回一个状态（比如“THTTP/1.1 200 OK”），以及请求的文件、错误信息等响应内容。



**HTTP的请求方法**

- GET：像指定资源发出“显示”请求，GET方法应该只用于读取数据。GET可能会被爬虫等随意访问

- HEAD：与GET方法一样，都是向服务器发去指定资源的请求，不过服务器不会传回资源的内容。好处在于不必传输内容，将获取到该资源的元数据

- POST：向指定资源提交数据，请求服务器进行处理（例如提交表单或者上传文件）。数据被包含在请求文本中

- PUT：向指定资源位置上传输最新内容

- DELETE：请求服务器删除Request-URL所标识的资源

- TRACE：回显服务器收到的请求，主要用于测试或诊断

- OPTIONS：这个方法可使服务器传回该资源所支持的所有HTTP请求方法。用“*”来代表资源名称向Web服务器发送OPTIONS请求，可以测试服务器共能是否正常。

- CONNECT：HTTP/1.1 协议中预留给能够将连接改为管道方式的代理服务器。通常用于SSL加密服务器的连接（经由非加密的HTTP代理服务器）。方法名称是区分大小写的。当某个请求所针对的资源不支持对应的请求方法的时候，服务器应当返回状态码405（Method Not Allowed），当服务器不认识或者不支持对应的请求方法的时候，应当返回状态码501（Not Implemented）。

  

#### 2 网页基础

##### 2.1 网页组成

网页是由 HTML 、 CSS 、JavaScript 组成的。

- HTML：F12开发者工具中的选项 Elements 中可以看到网页的源代码，这里展示的就是 HTML 代码。

- CSS：在Style标签页中，显示的是当前选中的HTML代码标签的CSS层叠样式，

- JavaScript：JavaScript 就厉害了，它在 HTML 代码中通常使用 <script> 进行包裹，可以直接书写在 HTML 页面中，也可以以文件的形式引入。

##### 2.2 HTML DOM

在 HTML 中，所有标签定义的内容都是节点，他们构成了一个HTML DOM树

- 整个文档是一个文档节点
- 每个 HTML 元素是元素节点
- HTML 元素内的文本是文本节点
- 每个 HTML 属性是属性节点
- 注释是注释节点

通过 HTML DOM，树中的所有节点均可通过 JavaScript 进行访问。所有 HTML 元素（节点）均可被修改，也可以创建或删除节点。

<img src="upload/image-20200421170849932.png" alt="image-20200421170849932" style="zoom:50%;" />

##### 2.3 CSS

在CSS中，我们使用CSS选择器来定位节点。例如，上例中 div 节点的 id 为 container ，那么就可以表示为 #container ，其中 # 开头代表选择 id ，其后紧跟 id 的名称。另外，如果我们想选择 class 为 wrapper 的节点，便可以使用 .wrapper ，这里以点 . 开头代表选择 class ，其后紧跟 class 的名称。



#### 3 使用开发者工具检查网页

Chrome的开发者模式（快捷键：F12）为用户提供了下面几组工具。

- Elements：允许用户从浏览器的角度来观察网页，用户可以借此看到Chrome渲染页面所需要的HTML、CSS和DOM（Document Object Model）对象。
- Network：可以看到网页向服务气请求了哪些资源、资源的大小以及加载资源的相关信息。此外，还可以查看HTTP的请求头、返回内容等。
- Source：即源代码面板，主要用来调试JavaScript。
- Console：即控制台面板，可以显示各种警告与错误信息。在开发期间，可以使用控制台面板记录诊断信息，或者使用它作为shell在页面上与JavaScript交互。
- Performance：使用这个模块可以记录和查看网站生命周期内发生的各种事情来提高页面运行时的性能。
- Memory：这个面板可以提供比Performance更多的信息，比如跟踪内存泄漏。
- Application：检查加载的所有资源。
- Security：即安全面板，可以用来处理证书问题等。

##### 3.1 Elements

在 Elements 中，右击元素有对应的快捷键，其中Copy XPath功能为爬虫提供了很多便利

##### 3.2 Network

在Network中可以查看网页加载网络资源地过程和相关信息。请求的每个资源在“Network”表格中显示为一行，对于某个特定的网络请求，可以进一步查看请求头、响应头及已经返回的内容等信息。对于需要填写并发送表单的网页而言（比如执行用户登录操作，以百度贴吧为例），在“Network”面板勾选“Preserve log”复选框，然后进行登录，就可以记录HTTP POST信息，查看发送的表单信息详情。之后在贴吧首页开启开发者工具后再登录时，就可以看到下图所示的信息，其中“Form Data”就包含向服务器发送的表单信息详情。

另外“Network”中的“Preview”也是比较常用，可以用来预览数据。



#### 4 requests.get()

这是一个网络爬虫程序普遍的过程：

- 访问站点；

- 定位所需的信息；
- 得到并处理信息。

##### 4.1 访问站点

```python
import requests
url = 'https://www.python.org/dev/peps/pep-0020/'
res = requests.get(url)
text = res.text
text
```

##### 4.2 定位所需要的信息

可以看到返回的其实就是开发者工具下Elements的内容，不过是字符串类型，接下来我们要用python的内置函数find来定位“python之禅”的索引，然后从这段字符串中取出它

通过观察网站，我们可以发现这段话在一个特殊的容器中，通过审查元素，使用快捷键Ctrl+shift+c快速定位到这段话也可以发现这段话包围在pre标签中，因此我们可以由这个特定用find函数找出具体内容

`<pre>` 标签可定义预格式化的文本。 被包围在`<pre>` 标签中的文本通常会保留空格和换行符。而文本也会呈现为等宽字体。

##### 4.3 得到并处理信息

```python
with open('zon_of_python.txt', 'w') as f:
    f.write(text[text.find('<pre')+28:text.find('</pre>')-1])
print(text[text.find('<pre')+28:text.find('</pre>')-1])
```

##### 4.4 此外我们也可以是用urllib完成上述操作

```python
import urllib
url = 'https://www.python.org/dev/peps/pep-0020/'
res = urllib.request.urlopen(url).read().decode('utf-8')
print(res[res.find('<pre')+28:res.find('</pre>')-1])
```

但其代码不够优雅，我选择requests

#### 5 requests.post()

##### 5.1 分析Post请求

打开金山词霸http://fy.iciba.com/，打开F12开发者工具，翻译一句话，例如“Beautiful is better than ugly.”

![image-20200421175411537](https://muyun-blog-pic.oss-cn-shanghai.aliyuncs.com/picgo/image-20200421175411537.png#vwid=1912&vhei=577)

会发现下面会有一个POST请求，我们需要用到的两部分信息是Request Headers中的User-Agent，以及From Data

<img src="https://muyun-blog-pic.oss-cn-shanghai.aliyuncs.com/picgo/image-20200421175842617.png#vwid=443&vhei=558" alt="image-20200421175842617"  />

- User-Agent: 

  Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36

- From Data

  f: auto

  t: auto

  w:Beautiful is better than ugly.



##### 5.2 使用代码来Post请求

```python
import requests
def translate(word):
    url="http://fy.iciba.com/ajax.php?a=fy"

    data={
        'f': 'auto',
        't': 'auto',
        'w': word,
    }
    
    headers={
        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36',
    }#User-Agent会告诉网站服务器，访问者是通过什么工具来请求的，如果是爬虫请求，一般会拒绝，如果是用户浏览器，就会应答。
    response = requests.post(url,data=data,headers=headers)     #发起请求
    json_data=response.json()   #获取json数据
    #print(json_data)
    return json_data
    
def run(word):    
    result = translate(word)['content']['out']   
    print(result)
    return result

def main():
    with open('zon_of_python.txt') as f:
        zh = [run(word) for word in f]

    with open('zon_of_python_zh-CN.txt', 'w') as g:
        for i in zh:
            g.write(i + '\n')
            
if __name__ == '__main__':
    main()
```

#### 6 request.get进阶：爬取豆瓣电影

```python
import requests
import os


def get_html(url):
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36"
        }
        res = requests.get(url, headers=headers)
        return res.text
    except:
        print("Failed!")


def extract(html):
    html = html.split('"')
    name = html[1]
    image = html[3]
    return name, image


if __name__ == "__main__":
    if not os.path.exists('image'):
        os.mkdir('image')

    items = []
    for i in range(10):
        url = "https://movie.douban.com/top250?start=" + str(i * 25)
        html = get_html(url)
        for i in range(25):
            html = html[html.find('alt')+3:]
            items.append(extract(html))

    with open('movie.txt', 'w', encoding='utf-8') as f:
        for i in range(250):
            item = items[i]
            f.write(str(i+1) + "." + item[0] + '\n')

    for i in range(250):
        item = items[i]
        r = requests.get(item[1])
        with open('image/' + str(i+1) + "." + str(item[0]) + '.jpg', 'wb') as f:
            f.write(r.content)

```



#### 7 使用API

##### 7.1 API简介

API（Application Programming Iterface）为开发者提供了方便友好的接口，不同的开发者用不同的语言都能获取相同的数据。目前API一般会以XML（Extensible Markup Language，可拓展标记语言）或者JSON（JavaScript Object Notation）格式来返回服务器响应，其中JSON数据格式越来越受到人们的欢迎

##### 7.2 百度地图API为例

http://lbsyun.baidu.com/apiconsole/key 进行开发者注册

创建应用得到密钥AK

<img src="https://muyun-blog-pic.oss-cn-shanghai.aliyuncs.com/picgo/image-20200421181404781.png#vwid=763&vhei=773" alt="image-20200421181404781" style="zoom:80%;" />

在下面的程序中填入密钥，运行后即可得到结果

```python
import requests

def getUrl(*address):
    ak = ''  ## 填入你的api key
    if len(address) < 1:
        return None
    else:
        for add in address:   
            url = 'http://api.map.baidu.com/geocoding/v3/?address={0}&output=json&ak={1}'.format(add,ak)  
            yield url
            

def getPosition(url):
    '''返回经纬度信息'''
    res = requests.get(url)
    #print(res.text)
    json_data = eval(res.text)
    
    if json_data['status'] == 0:
        lat = json_data['result']['location']['lat'] #纬度
        lng = json_data['result']['location']['lng'] #经度
    else:
        print("Error output!")
        return json_data['status']
    return lat,lng

if __name__ == "__main__":
    address = ['北京市清华大学','北京市北京大学','保定市华北电力大学','上海市复旦大学','武汉市武汉大学']
    for add in address:
        add_url = list(getUrl(add))[0]
        print('url:', add_url)
        try:
            lat,lng = getPosition(add_url)
            print("{0}|经度:{1}|纬度:{2}.".format(add,lng,lat))
        except Error as e:
            print(e)
```

#### 8. JavaScript与AJAX技术

##### 8.1 简介 

 如果利用Requests库和BeautifulSoup来采集一些大型电商网站的页面，可能会发现一个令人疑感的现象，那就是对于同一个URL、同一个页面，抓取到的内容却与浏览器中看到的内容有所不同。比如有的时候去寻找某一个`<div>`元素，却发现Python程序报出异常，查看requests.get()方法的响应数据也没有看到想要的元素信息。这其实代表着网页数据抓取的一个关键问题——开发者通过程序获取到的HTTP响应内容都是原始的HTML数据，但浏览器中的页面其实是在HTML的基础上，经过JavaScript进一步加工和处理后生成的效果。比如淘宝的商品评论就是通过JavaScript获取JSON数据，然后“嵌入”到原始HTML中并呈现给用户。这种在页面中使用JavaScript的网页对于20世纪90年代的web界面而言几乎是天方夜测，但在今天，以AJAX（Asynchronous JavaScript and XML，异步JavaScript与XML）技术为代表的结合JavaScript、CSS、HTML等语言的网页开发技术已经成为绝对的主流。

为了避免为每一份要呈现的网页内容都准备一个HTML，网站开发者们开始考虑对网页的呈现方式进行变革。在JavaScript问世之初，Google公司的Gmail邮箱网站是第一个大规模使用JavaScript加载网页数据的产品，在此之前，用户为了获取下一页的网页信息，需要访问新的地址并重新加载整个页面。但新的Gmail则做出了更加优雅的方案，用户只需要单击“下一页”按钮，网页就（实际上是浏览器）会根据用户交互来对下一页数据进行加载，而这个过程并不需要对整个页面（HTML）的刷新。换句话说，JavaScript使得网页可以灵活地加载其中一部分数据。后来，随着这种设计的流行，“AJAX”这个词语也成为一个“术语”，Gmail作为第一个大规模使用这种模式的商业化网站，也成功引领了被称之为“Web2.0”的潮流。

##### 8.2 JavaScript 语言

- 动态语言 动态语言是指程序在运行时可以改变其结构：新的函数可以被引进，已有的函数可以被删除等在结构上的变化。JavaScript便是一个动态语言。除此之外如Ruby、Python等也都属于动态语言，而C、C++等语言则不属于动态语言。比如在JavaScript中可以在对象定义之后动态的为其添加属性和方法

- 脚本语言 脚本语言是为了缩短传统的编写-编译-链接-运行（edit-compile-link-run）过程而创建的计算机编程语言，只在被调用时进行解释或编译，然后执行。
- 弱类型 弱/强类型指的是语言类型系统的类型检查的严格程度，弱类型的语言在声明变量的时候不必进行变量类型的确定，语言的运行时会隐式做数据类型转换，对于弱类型语言来说，不同类型的变量可以进行直接运算，而强类型的则不可以。

##### 8.3 AJAX 

AJAX技术与其说是一种“技术”，不如说是一种“方案”。如上文所述，在网页中使用JavaScript 加载页面中数据的过程，都可以看作AJAX技术。AJAX技术改变了过去用户浏览网站时一个请求对应一个页面的模式，允许浏览器通过异步请求来获取数据，从而使得一个页面能够呈现并容纳更多的内容，同时也就意味着更多的功能。只要用户使用的是主流的浏览器，同时允许浏览器执行JavaScript，用户就能够享受网页中的AJAX内容。

比较尴尬的是，爬虫一般不能执行包括“加载新内容”或者“跳到下一页”等功能在内的各类写在网页中的JavaScript代码。如本节开头所述，爬虫会获取网站的原始HTML页面，由于它没有像浏览器一样的执行JavaScript脚本的能力，因此也就不会为网页运行JavaScript。最终，爬虫爬取到的结果就会和浏览器里显示的结果有所差异，很多时候便不能直接获得想要的关键信息。为解决这个尴尬处境，基于Python编写的爬虫程序可以做出两种改进，一种是通过分析AJAX内容（需要开发者手动观察和实验），观察其请求目标、请求内容和请求的参数等信息，最终编写程序来模拟这样的JavaScript 请求，从而获取信息（这个过程也可以叫作“逆向工程”）。另外一种方式则比较取巧，那就是直接模拟出浏览器环境，使得程序得以通过浏览器模拟工具“移花接木”，最终通过浏览器渲染后的页面来获得信息。这两种方式的选择与JavaScript在网页中的具体使用方法有关。

#### 9. 参考资料

- [https://github.com/datawhalechina/team-learning/tree/master/Python%E7%88%AC%E8%99%AB%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5](https://github.com/datawhalechina/team-learning/tree/master/Python爬虫编程实践)