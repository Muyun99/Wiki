---
title: Beautiful-soup4、Xpath、re
date: 2021-03-09 21:21:23
permalink: /pages/ad2d26/
categories:
  - 技术文章
  - 爬虫实践
tags:
  - 
---

# Python 爬虫 - 02 Beautiful soup4、Xpath、re

#### 1. Beautiful soup库

##### 1.1 Beautiful soup4 简介

- Beautiful Soup 是一个HTML/XML 的解析器，主要用于解析和提取 HTML/XML 数据。 
- 它基于HTML DOM 的，会载入整个文档，解析整个DOM树，因此时间和内存开销都会大很多，所以性能要低于lxml。
- BeautifulSoup 用来解析 HTML 比较简单，API非常人性化，支持CSS选择器、Python标准库中的HTML解析器，也支持 lxml 的 XML解析器。
- BeautifulSoup4 简单容易比较上手，但其匹配效率还是远远不如正则以及xpath的，一般不推荐使用，推荐正则的使用。

##### 1.2 从零创建一个bs对象

- pip install beautifulsoup4
- from bs4 import BeautifulSoup
- soup = BeautifulSoup(html, 'html.parser')

##### 1.3 BS 库的基本元素

| 元素名          | 释义                         |
| --------------- | ---------------------------- |
| Tag             | 标签，最基本的信息组织单元   |
| Name            | 标签的名字                   |
| Attributes      | 标签的属性，字典形式组织数据 |
| NavigableString | 标签内非属性字符串           |
| Comment         | 标签内字符串的注释部分       |

```python
# 导入bs4库
from bs4 import BeautifulSoup
import requests # 抓取页面

r = requests.get('https://python123.io/ws/demo.html') # Demo网址
demo = r.text  # 抓取的数据
print(demo)
# 解析HTML页面
soup = BeautifulSoup(demo, 'html.parser')  # 抓取的页面数据；bs4的解析器
# 有层次感的输出解析后的HTML页面
print(soup.prettify())

def test1():
    print(soup.a)
    print(soup.title)
    print(soup.a.name)
    print(soup.a.parent.name)
    print(soup.p.parent.name)

    tag = soup.a
    print(tag.attrs)
    print(tag.attrs['class'])
    print(type(tag.attrs))

    print(soup.a.string)
    print(type(soup.a.string))
    print(type(soup.p.string))
```

- bs4库将任何HTML输入都变成utf‐8编码，解析无障碍

##### 1.4 基于 bs4 库的 HTML 内容遍历方法

> HTML基本格式:`<>…`构成了所属关系，形成了标签的树形结构
>
> - 标签树的下行遍历
>   - .contents 子节点的列表，将``所有儿子节点存入列表
>   - .children 子节点的迭代类型，与.contents类似，用于循环遍历儿子节点
>   - .descendants 子孙节点的迭代类型，包含所有子孙节点，用于循环遍历
> - 标签树的上行遍
>   - .parent 节点的父亲标签
>   - .parents 节点先辈标签的迭代类型，用于循环遍历先辈节点
> - 标签树的平行遍历
>   - .next_sibling 返回按照HTML文本顺序的下一个平行节点标签
>   - .previous_sibling 返回按照HTML文本顺序的上一个平行节点标签
>   - .next_siblings 迭代类型，返回按照HTML文本顺序的后续所有平行节点标签
>   - .previous_siblings 迭代类型，返回按照HTML文本顺序的前续所有平行节点标签

```python
# 标签的下行遍历
def test2():
    print(soup.body.content)#返回标签树的body标签下的节点
    print(soup.head)#返回head标签
    for child in soup.body.children:#遍历儿子节点
        print(child)
    for child in soup.body.descendants:#遍历子孙节点
        print(child)

# 标签树的上行遍历
def test3():
    print(soup.title.parent)
    print(soup.parent)
    for parent in soup.a.parents: # 遍历先辈的信息
        if parent is None:
            print(parent)
        else:
            print(parent.name)

# 标签树的平行遍历
def test4():
    print(soup.a.next_sibling)#a标签的下一个标签
    print(soup.a.next_sibling.next_sibling)#a标签的下一个标签的下一个标签
    print(soup.a.previous_sibling)#a标签的前一个标签
    print(soup.a.previous_sibling.previous_sibling)#a标签的前一个标签的前一个标签
    for sibling in soup.a.next_siblings:#遍历后续节点
        print(sibling)
    for sibling in soup.a.previous_sibling:#遍历之前的节点
        print(sibling)
```

##### 1.5 基于bs4 库的HTML 内容的查找方法

> - <>.find_all(name, attrs, recursive, string, **kwargs)
>   - 参数：
>   - ∙ name : 对标签名称的检索字符串
>   - ∙ attrs: 对标签属性值的检索字符串，可标注属性检索
>   - ∙ recursive: 是否对子孙全部检索，默认True
>   - ∙ string: <>…</>中字符串区域的检索字符串
>     - 简写：
>     - ``(..) 等价于 ``.find_all(..)
>     - soup(..) 等价于 soup.find_all(..)
> - 扩展方法：
>   - <>.find() 搜索且只返回一个结果，同.find_all()参数
>   - <>.find_parents() 在先辈节点中搜索，返回列表类型，同.find_all()参数
>   - <>.find_parent() 在先辈节点中返回一个结果，同.find()参数
>   - <>.find_next_siblings() 在后续平行节点中搜索，返回列表类型，同.find_all()参数
>   - <>.find_next_sibling() 在后续平行节点中返回一个结果，同.find()参数
>   - <>.find_previous_siblings() 在前序平行节点中搜索，返回列表类型，同.find_all()参数
>   - <>.find_previous_sibling() 在前序平行节点中返回一个结果，同.find()参数

```python
# 爬取中国最好大学排名
```

#### 2. Xpath 解析

##### 2.1 Xpath 简介

- XPath即为XML路径语言（XML Path Language），它是一种用来确定XML文档中某部分位置的语言。
- 在XPath中，有七种类型的节点：元素、属性、文本、命名空间、处理指令、注释以及文档（根）节点。
- XML文档是被作为节点树来对待的。

> XPath使用路径表达式在XML文档中选取节点。节点是通过沿着路径选取的。下面列出了最常用的路径表达式：
>
> - nodename 选取此节点的所有子节点。
> - / 从根节点选取。
> - //	从匹配选择的当前节点选择文档中的节点，而不考虑它们的位置。
> - .	选取当前节点。
> - ..	选取当前节点的父节点。
> - @	选取属性。
> - /text() 提取标签下面的文本内容
>   - 如：
>   - /标签名 逐层提取
>   - /标签名 提取所有名为<>的标签
>   - //标签名[@属性=“属性值”](vscode-resource://file///d%3A/From Github/team-learning-master/Python爬虫编程实践/task2/) 提取包含属性为属性值的标签
>   - @属性名 代表取某个属性名的属性值
> - 详细学习：https://www.cnblogs.com/gaojun/archive/2012/08/11/2633908.html

##### 2.2 使用 lxml 解析（尚未完成）

```

```

#### 3. Re 库解析(尚未完成)